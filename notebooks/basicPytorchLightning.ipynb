{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'combine_datasets' from 'data_preprocessing' (/Users/tonderaimadamba/nlp-classification/data_preprocessing.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m \n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdata_preprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m combine_datasets\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m OneHotEncoder\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompose\u001b[39;00m \u001b[39mimport\u001b[39;00m ColumnTransformer\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'combine_datasets' from 'data_preprocessing' (/Users/tonderaimadamba/nlp-classification/data_preprocessing.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from data_preprocessing import combine_datasets\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import torch.nn as nn\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "from transformers import DistilBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combine_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"CVD_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.loc[:, ~df.columns.isin([\"Heart_Disease\"])]\n",
    "targets = df.loc[:,df.columns.isin([\"Heart_Disease\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Here is your dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, features, targets, train=False,test=False,val=False, transform=None):\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.val = val\n",
    "        \n",
    "        self.raw_features = features \n",
    "        self.raw_targets = targets\n",
    "        # Perform one-hot encoding on the features\n",
    "        self.column_transformer = ColumnTransformer([('one_hot_encoder', \n",
    "                                                        OneHotEncoder(sparse=False), \n",
    "                                                        self.raw_features.select_dtypes(include=['object']).columns)],\n",
    "                                                        remainder='passthrough')\n",
    "        self.new_features = self.column_transformer.fit_transform(self.raw_features)\n",
    "        self.label_binarizer = LabelEncoder()\n",
    "        self.new_targets =  self.label_binarizer.fit_transform(self.raw_targets.values)\n",
    "        \n",
    "        self._split_data()\n",
    "\n",
    "        self.targets = self.new_targets[self.indices]   \n",
    "        self.features = self.new_features[self.indices]\n",
    "        self.transform = transform \n",
    "        \n",
    "    def _split_data(self):\n",
    "        idx = list(range(len(self.raw_targets)))\n",
    "        train_idx, val_test_idx = train_test_split(\n",
    "                                idx,\n",
    "                                train_size=0.8,\n",
    "                                stratify=self.raw_targets,\n",
    "                                random_state=500)\n",
    "        \n",
    "        test_idx,  val_idx, = train_test_split(\n",
    "                                val_test_idx,\n",
    "                                train_size=0.8,\n",
    "                                random_state=500)\n",
    "        \n",
    "        # return train_idx, test_idx,  val_idx \n",
    "\n",
    "        if self.train:\n",
    "            self.indices = train_idx\n",
    "            \n",
    "        elif self.test:\n",
    "            self.indices =  test_idx\n",
    "            \n",
    "        elif self.val:\n",
    "            self.indices =  val_idx\n",
    "        else :\n",
    "            self.indices = idx\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.features[index], self.targets[index]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "\n",
    "    \n",
    "class to_tensor:\n",
    "    def __call__(self,sample):\n",
    "        features, targets= sample\n",
    "        return torch.tensor(features,dtype=torch.float32,device='mps:0'), torch.tensor(targets ,dtype=torch.int32,  device='mps:0')\n",
    "    \n",
    "    \n",
    "def transformInput(trainDataset,this_dict):\n",
    "    return torch.tensor(trainDataset.column_transformer.transform(this_dict),dtype=torch.float32,device='mps:0')\n",
    "    \n",
    "#The loader outputs a tensor float64 mac uses mps:0 and float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Here is your PyTorch Lightning model\n",
    "class LitNetwork(pl.LightningModule):\n",
    "    def __init__(self, trainDataLoader, testDataLoader, valDataLoader):\n",
    "        super(LitNetwork, self).__init__()\n",
    "        self.train_ds = trainDataLoader\n",
    "        self.test_ds = testDataLoader\n",
    "        self.val_ds = valDataLoader\n",
    "        self.linear1 = nn.Linear(48, 25)\n",
    "        self.linear2 = nn.Linear(25, 2)\n",
    "        # self.label_binarizer = trainDataLoader.\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = nn.functional.cross_entropy(y_hat, y)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        preds = torch.argmax(y_hat, dim=1)\n",
    "        acc = torchmetrics.functional.accuracy(preds,  y)\n",
    "\n",
    "        # Logging to TensorBoard by default\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.02)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.train_ds\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.test_ds  # return your dataloader\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        return self.val_ds  # return your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel():\n",
    "        trainDataset = MyDataset(features, targets,train=True, transform=to_tensor())\n",
    "        testDataset = MyDataset(features, targets, test=True, transform=to_tensor())\n",
    "        valDataset = MyDataset(features, targets, val=True, transform=to_tensor())\n",
    "\n",
    "        trainDataLoader = DataLoader(trainDataset, batch_size=5000, shuffle=True)\n",
    "        testDataLoader = DataLoader(testDataset, batch_size=5000, shuffle=True)\n",
    "        valDataLoader = DataLoader(valDataset, batch_size=5000, shuffle=True)\n",
    "\n",
    "        model = LitNetwork(trainDataLoader,testDataLoader,valDataLoader)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/tonderaimadamba/Library/Python/3.9/lib/python/site-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tonderaimadamba/Library/Python/3.9/lib/python/site-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tonderaimadamba/Library/Python/3.9/lib/python/site-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/tonderaimadamba/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/configuration_validator.py:68: UserWarning: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "  rank_zero_warn(\"You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\")\n",
      "\n",
      "  | Name    | Type   | Params\n",
      "-----------------------------------\n",
      "0 | linear1 | Linear | 1.2 K \n",
      "1 | linear2 | Linear | 52    \n",
      "-----------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "/Users/tonderaimadamba/Library/Python/3.9/lib/python/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4d43de5f05140a69b554b5758328a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=1,accelerator=\"mps\")\n",
    "model = loadModel()\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bm = {'General_Health' : 'Very Good',\n",
    "    'Checkup' : 'Within the past year', \n",
    "    'Exercise' : 'No', \n",
    "    'Skin_Cancer' : 'No', \n",
    "    'Other_Cancer' : 'No',\n",
    "    'Depression' : 'No', \n",
    "    'Diabetes' : 'Yes',\n",
    "    'Arthritis' : 'No', \n",
    "    'Sex' : 'Male', \n",
    "    'Age_Category' : '70-74',\n",
    "    'Height_(cm)': 175.0, \n",
    "    'Weight_(kg)' : 75.11, \n",
    "    'BMI' : 1, \n",
    "    'Smoking_History' : 'Yes',\n",
    "    'Alcohol_Consumption' : 0.0, \n",
    "    'Fruit_Consumption' : 30.0,\n",
    "    'Green_Vegetables_Consumption' : 0.0, \n",
    "    'FriedPotato_Consumption' : 4.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,df):\n",
    "    data_df = model.train_ds.dataset.column_transformer.transform(df)\n",
    "    tensor_df = torch.tensor(data_df,dtype=torch.float32,device='mps:0')\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    model.to(mps_device)\n",
    "    with torch.no_grad():\n",
    "        pred = model(tensor_df)\n",
    "    return  nn.functional.softmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"example.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8g/g8wt7qjs1d162gzvz0xhgr3c0000gp/T/ipykernel_71092/1454827676.py:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return  nn.functional.softmax(pred)\n"
     ]
    }
   ],
   "source": [
    "new = pd.DataFrame(predict(model,features).cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
